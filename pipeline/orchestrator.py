import os
import time
import logging
import subprocess
from pathlib import Path
from dotenv import load_dotenv
import importlib.util
import sys
from continuous_setup import start_continuous_setup
from planning_agent import start_planning
from execution_agent import start_execution_agent
from validation_agent import start_validation_agent
from finalization_agent import start_finalization_agent
from utils.forge_interface import ForgeInterface
from utils.subprocess_handler import SubprocessHandler

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

def wait_for_analysis_files(repo_path: str, timeout: int = 300) -> bool:
    """
    Wait for the analysis files to be generated by continuous_setup.py.
    Returns True if files are found, False if timeout is reached.
    """
    analysis_dir = os.path.join(repo_path, 'analysis')
    start_time = time.time()
    required_files = {'codebase_overview.txt', 'file_tree.txt'}
    
    while time.time() - start_time < timeout:
        if os.path.exists(analysis_dir):
            files = set(os.listdir(analysis_dir))
            if required_files.issubset(files):
                # Also check if there are any *_analysis.txt files
                if any(f.endswith('_analysis.txt') for f in files):
                    logging.info("All required analysis files have been generated")
                    return True
        time.sleep(1)  # Check every second
    
    logging.error(f"Timeout waiting for analysis files after {timeout} seconds")
    return False

def import_module_from_path(module_name: str, module_path: str):
    """Import a module from a file path"""
    spec = importlib.util.spec_from_file_location(module_name, module_path)
    module = importlib.util.module_from_spec(spec)
    sys.modules[module_name] = module
    spec.loader.exec_module(module)
    return module

def run_continuous_setup(repo_path: str):
    """Run continuous setup and return its handlers"""
    # Get the pipeline directory path
    pipeline_dir = os.path.dirname(os.path.abspath(__file__))
    
    # Import continuous_setup module
    continuous_setup = import_module_from_path(
        'continuous_setup',
        os.path.join(pipeline_dir, 'continuous_setup.py')
    )
    
    # Run continuous setup and get handlers
    subprocess_handler, forge_interface, observer = continuous_setup.run_continuous_setup()
    
    return subprocess_handler, forge_interface, observer

def orchestrate_pipeline(repo_path: str, user_query: str):
    """
    Orchestrates the entire pipeline from setup to finalization.
    
    Flow:
    1. Continuous Setup - Monitor and analyze codebase
    2. Planning - Generate implementation plan
    3. Execution - Execute code changes
    4. Validation - Validate changes with commands
    5. Finalization - Run final steps and cleanup
    """
    
    try:
        # Initialize forge interface
        subprocess_handler = SubprocessHandler(Path(repo_path))
        forge_interface = ForgeInterface(subprocess_handler)
        
        # Start continuous setup
        logging.info("Starting continuous setup...")
        setup_state = start_continuous_setup(repo_path)
        
        # Start planning
        logging.info("Starting planning phase...")
        planning_state = start_planning(user_query, setup_state)
        
        # Start forge for execution and validation
        subprocess_handler.start_forge(
            os.getenv("OPENAI_API_KEY"),
            planning_state.get("files_to_edit", [])
        )
        
        # Execute code changes
        logging.info("Starting execution phase...")
        execution_state = start_execution_agent(planning_state, forge_interface)
        
        # If execution was successful, proceed to validation
        if execution_state.get('code_query_decision') == 'END':
            logging.info("Starting validation phase...")
            validation_state = start_validation_agent(
                planning_state['implementation_plan'],
                forge_interface
            )
            
            # If validation was successful, proceed to finalization
            if validation_state.get('validation_status') == 'END':
                logging.info("Starting finalization phase...")
                finalization_state = start_finalization_agent(
                    planning_state['implementation_plan']
                )
                
                # Combine all states for final result
                final_state = {
                    'setup_state': setup_state,
                    'planning_state': planning_state,
                    'execution_state': execution_state,
                    'validation_state': validation_state,
                    'finalization_state': finalization_state
                }
            else:
                logging.error("Validation phase did not complete successfully")
                final_state = {
                    'setup_state': setup_state,
                    'planning_state': planning_state,
                    'execution_state': execution_state,
                    'validation_state': validation_state
                }
        else:
            logging.error("Execution phase did not complete successfully")
            final_state = {
                'setup_state': setup_state,
                'planning_state': planning_state,
                'execution_state': execution_state
            }
        
        return final_state
        
    except Exception as e:
        logging.error(f"Pipeline failed: {str(e)}")
        raise

def main():
    # Load environment variables
    load_dotenv()
    
    # Get the pipeline directory path
    pipeline_dir = os.path.dirname(os.path.abspath(__file__))
    workspace_dir = os.path.dirname(pipeline_dir)
    
    # Get the repository path
    repo_path = os.path.join(workspace_dir, 'repo')
    
    # Start continuous setup and get handlers
    logging.info("Starting continuous setup process...")
    subprocess_handler, forge_interface, observer = run_continuous_setup(repo_path)
    
    # Wait for analysis files to be generated
    logging.info("Waiting for analysis files to be generated...")
    if not wait_for_analysis_files(repo_path):
        observer.stop()
        subprocess_handler.close_forge()
        raise TimeoutError("Failed to generate analysis files")
    
    # Give a little extra time for everything to be ready
    time.sleep(5)
    
    # Orchestrate the pipeline
    logging.info("Starting pipeline orchestration...")
    try:
        # Orchestrate the pipeline
        final_state = orchestrate_pipeline(repo_path, os.getenv("USER_QUERY"))
        
        # Print the final state
        print("\nFinal State:")
        print("=" * 80)
        print(final_state)
        print("=" * 80)
        
    except Exception as e:
        logging.error(f"Error during pipeline orchestration: {str(e)}")
        observer.stop()
        subprocess_handler.close_forge()
        raise
    
    # Keep monitoring until interrupted
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        logging.info("Shutting down...")
        observer.stop()
        subprocess_handler.close_forge()

if __name__ == "__main__":
    main()